# %%import numpy as npimport pandas as pdfrom Q_matrix import Q_matrixfrom Ematrix import E_matrixfrom P_matrix import P_matrixfrom L_i import L_ip = [-3,-4,-4,-5,  1.1,0,1.2,1.4,  2,3,4,5, -.01,.005,.005,.002]no_qpars = 16functions = ['gompertz','gompertz','gompertz','gompertz']age_like='age'death_states = [3]censored_state = [-1,-2]corresponding_censored_states = [[1,2],[1,2,3]]lt_states = [1,2]Qm = np.array([[0,.1,0.1],      [0.1,0,.1],      [0,0,0]])covariates_name = ["age","x",'y']j=0d = {'id':[1,1,1,2,2,2,3,3,3,4,4,4]   ,'age': [2,2.2,2.4, 3,3.2,3.4, 4,4.2,4.4, 2,2.2,2.5], 'x': [.1,.1,.1 ,  -.3,-.3,-.3,  -.4,-.4,-.4,   .1,.1,.1],'y': [1,1,1, 2,2,2, 3,3,3, 1,1,1],     'state':[1,2,3, 2,2,3, -1,1,2, 1,-1,2 ]  }dt = pd.DataFrame(data=d)Q_matrix(p,no_qpars,Qm,covariates_name,0,dt,functions,age_like)Use_misclass_matrix=Trueuse_given_initial_prob=Falsep_e=[-1.5, -2.0,  0.3 , 0.2,  0.4,  0.5]no_epars=6E_covariates_name=["age","x"]ematrix = np.array([[0,0.1,0],           [0.1,0,0],           [0,0,0]]           )grid_length = 0.1lt_assumption_age = 0.1dt_q=dt.groupby(covariates_name).size().reset_index(name='counts')qlength = len(dt_q.index)dt_q['row'] = np.arange(dt_q.shape[0])Q_list = [Q_matrix(p,no_qpars,Qm,covariates_name,j,dt_q,functions,age_like) for j in range(0, qlength )]dta_s = pd.merge(dt,dt_q,how = 'left')dta_s=dta_s.sort_values(by=['id','age'])dt_E=dt.groupby(E_covariates_name).size().reset_index(name='counts')dt_E['row_E'] = np.arange(dt_E.shape[0])e_length = len(dt_E.index)E_list=[E_matrix(p_e,no_epars,ematrix,j,dt_E,E_covariates_name) for j in range(0, e_length)]dta_s = pd.merge(dta_s,dt_E,how = 'left')dta_s=dta_s.sort_values(by=['id','age'])dta_p=dta_sdta_p['lead_time']=dta_s.groupby(['id'])['age'].shift(-1)dta_p['interval']=dta_p['lead_time']-dta_p['age']dta_p=dta_p.fillna(0)dt_p=dta_p.groupby(['row','interval']).size().reset_index(name='counts')dt_p['row_p'] = np.arange(dt_p.shape[0])plength = len(dt_p.index)dta_p=dta_p.drop(columns=['counts'])dta_p = pd.merge(dta_p,dt_p,how = 'left')dta_p=dta_p.sort_values(by=['id','age'])P_list=[P_matrix(Q_list,dt_p,j) for j in range(0,plength)]temp_dta = dt.copy()# Group by 'id' and apply transformationstemp_dta['order_rank'] = temp_dta.groupby('id')['age'].rank()temp_dta['min_age'] = temp_dta.groupby('id')['age'].transform('min')temp_dta['age']=temp_dta['min_age'] temp_dta['state_1'] = temp_dta['state']temp_dta = temp_dta[temp_dta['order_rank'] == 1]temp_dta_group = temp_dta.copy()temp_dta_group=temp_dta_group.groupby(['age','state']).size().reset_index(name='counts')dta_lt_age = list()for i in temp_dta_group.index:    ltdta=temp_dta_group.loc[[i]].reset_index(drop=True)            seqs_time = np.arange(lt_assumption_age, ltdta['age'][0], grid_length)    seqs_time =np.append(seqs_time,ltdta['age'])            state_dta =np.repeat(-1, len(seqs_time), axis=0)    state_dta[0]=1    state_dta[len(seqs_time)-1]=ltdta['state'][0]                ltdta=ltdta.drop(columns=['counts'])            ltdta=ltdta.loc[ltdta.index.repeat(len(seqs_time)    )].reset_index(drop=True)    ltdta[age_like] = seqs_time    ltdta['state'] = state_dta    if(len(age_like)>0):        ltdta[age_like] = seqs_time                ltdta['order_rank'] = 1    ltdta['min_age'] = max(seqs_time)    ltdta['state_1']  = state_dta[len(state_dta)-1]    dta_lt_age.append(ltdta)dta_lt_age=pd.concat(dta_lt_age).reset_index(drop=True) temp_dta = temp_dta.drop(columns =['age','state',age_like  ] )dta_lt_temp = pd.merge(dta_lt_age,temp_dta,how = 'left')dta_lt_temp = dta_lt_temp.drop(columns =['order_rank','state_1',"min_age"  ] )dt_lt_q=dta_lt_temp.groupby(covariates_name).size().reset_index(name='counts')qlength = len(dt_lt_q.index)dt_lt_q['row'] = np.arange(dt_lt_q.shape[0])Q_lt_list = [Q_matrix(p,no_qpars,Qm,covariates_name,j,dt_lt_q,functions,age_like) for j in range(0, qlength )]dta_lt_s = pd.merge(dta_lt_temp,dt_lt_q,how = 'left')dta_lt_s=dta_lt_s.sort_values(by=['id','age'])dta_lt_s=dta_lt_s.sort_values(by=['id','age'])dta_lt_p=dta_lt_sdta_lt_p['lead_time']=dta_lt_s.groupby(['id'])['age'].shift(-1)dta_lt_p['interval']=dta_lt_p['lead_time']-dta_lt_p['age']dta_lt_p=dta_lt_p.fillna(0)dt_lt_p=dta_lt_p.groupby(['row','interval']).size().reset_index(name='counts')dt_lt_p['row_p'] = np.arange(dt_lt_p.shape[0])plength_lt = len(dt_lt_p.index)dta_lt_p=dta_lt_p.drop(columns=['counts'])dta_lt_p = pd.merge(dta_lt_p,dt_lt_p,how = 'left')dta_lt_p=dta_lt_p.sort_values(by=['id','age'])P_lt_list=[P_matrix(Q_lt_list,dt_lt_p,j) for j in range(0,plength_lt)]L_i(dta_p=dta_p,i=3,Q_list=Q_list,P_list=P_list,death_states=death_states,censored_state=censored_state    ,corresponding_censored_states=corresponding_censored_states,    E_list=E_list,E_covariates_name=E_covariates_name,no_epars=no_epars,    ematrix=ematrix,use_given_initial_prob=use_given_initial_prob,p_e=p_e,    Use_misclass_matrix=Use_misclass_matrix)