import numpy as npfrom Q_matrix import Q_matrix_torchfrom Ematrix import E_matrix_torchfrom P_matrix import P_matrix_torchfrom mat import mat_torchfrom L_i import L_i_torchimport torchdef loglikelihood_torch(*,p0,covariates_name,no_qpars,no_epars,constrain,Qm,functions,age_like,E_covariates_name,ematrix,death_states,censored_state ,corresponding_censored_states, use_given_initial_prob,Use_misclass_matrix,initial_prob,dt_q, qlength,plength,dt_E,e_length,dt_q_columns,dt_E_columns,dt_p, dt_p_columns,dta_p_tensor,dta_p_mats,dta_p_mats_columns,initial_state,initial_E ,**kwargs ):    p = p0[0:(no_qpars)]    p = p[constrain-1]    p_e=p0[max(constrain):(len(p0))]            if len(covariates_name)>0:        Q_list = torch.stack([Q_matrix_torch(p,no_qpars,Qm,covariates_name,j,dt_q,functions,age_like,dt_q_columns) for j in range(0, qlength )])    else:        j=0        Q_list = torch.stack([Q_matrix_torch(p, no_qpars, Qm, covariates_name, j, dt_q, functions, age_like,dt_q_columns)])        E_list = [E_matrix_torch(p_e, no_epars, ematrix, j, dt_E, E_covariates_name,dt_E_columns) for j in range(0, e_length)]    P_list=[P_matrix_torch(Q_list, dt_p, dt_p_columns, j) for j in range(0,plength)]    mat_list=torch.stack([mat_torch(Q_list, dta_p_mats, P_list, death_states, censored_state, corresponding_censored_states, E_list,  dta_p_mats_columns,j) for j in range(0,dta_p_mats.shape[0])])    out = []    for j in range(0, len(dta_p_tensor)):        idx = dta_p_tensor[j]        if len(idx) == 1:            # single matrix → return it directly            result = mat_list[idx[0]]        else:            # multiple matrices → multiply            result = torch.linalg.multi_dot(tuple(mat_list[i] for i in idx))        out.append(result)    mat_li = torch.stack(out)    L_i_torch(mat_li,    use_given_initial_prob,    Use_misclass_matrix=Use_misclass_matrix,    initial_prob=initial_prob,    initial_state=initial_state,    initial_E=initial_E,    E_list=E_list,    i=0)    li_stack=torch.stack([L_i_torch(mat_li,    use_given_initial_prob,    Use_misclass_matrix=Use_misclass_matrix,    initial_prob=initial_prob,    initial_state=initial_state,    initial_E=initial_E,    E_list=E_list,    i=i) for i in range(0,len(mat_li) )  ])    Log_l = -torch.sum(li_stack)    #print(p)    print(Log_l)    return Log_ldef objective_top(p, fixed):    return loglikelihood(p0=np.asarray(p), **fixed)